# TDD vs LLM: Prova Estat√≠stica de Efic√°cia

Este projeto demonstra estatisticamente que o uso de **Test-Driven Development (TDD)** melhora significativamente a precis√£o das respostas geradas por Large Language Models (LLMs).

## üìã Vis√£o Geral

O projeto compara duas abordagens:
1. **Baseline**: Respostas geradas diretamente pelo LLM sem refinamento
2. **TDD**: Respostas geradas e refinadas iterativamente usando testes como feedback

## üéØ Como Provar que TDD Ajuda

### 1. Pipeline TDD com Refinamento Iterativo

O arquivo `pipeline_tdd_improved.py` implementa um pipeline que:
- Gera respostas iniciais do LLM
- Executa testes de valida√ß√£o (factual e coer√™ncia)
- **Refina automaticamente** respostas que falham nos testes
- Itera at√© que os testes passem ou atinja o limite de itera√ß√µes

### 2. An√°lise Estat√≠stica Robusta

O arquivo `statistical_analysis.py` fornece:
- **M√©tricas comparativas**: Acur√°cia factual, coer√™ncia e geral
- **Testes de signific√¢ncia estat√≠stica**: Z-tests para propor√ß√µes
- **P-values**: Para determinar se as melhorias s√£o estatisticamente significativas
- **Relat√≥rio JSON**: Com todos os dados para an√°lise posterior

### 3. Visualiza√ß√µes

O arquivo `visualize_results.py` gera:
- Gr√°ficos de compara√ß√£o entre baseline e TDD
- Gr√°ficos de melhoria percentual
- Gr√°ficos de signific√¢ncia estat√≠stica
- Relat√≥rio HTML interativo

## üöÄ Como Usar

### Passo 1: Configurar API Key

Edite `pipeline_tdd_improved.py` e `generate_responses.py` e substitua `"SUA_CHAVE_GEMINI"` pela sua chave da API do Google Gemini.

### Passo 2: Gerar Respostas Baseline

```bash
python generate_responses.py
```

Isso gera `responses_raw.json` com respostas brutas do LLM.

### Passo 3: Processar com TDD

```bash
python pipeline_tdd_improved.py
```

Isso gera `validated_tdd_improved.json` com respostas refinadas usando TDD.

### Passo 4: An√°lise Estat√≠stica

```bash
python statistical_analysis.py
```

Isso gera:
- `statistical_report.json`: Relat√≥rio completo em JSON
- Sa√≠da no console com m√©tricas e testes de signific√¢ncia

### Passo 5: Visualiza√ß√µes

```bash
python visualize_results.py
```

Isso gera:
- `comparison_chart.png`: Gr√°fico de compara√ß√£o
- `improvement_chart.png`: Gr√°fico de melhoria
- `significance_chart.png`: Gr√°fico de signific√¢ncia
- `report.html`: Relat√≥rio HTML interativo

### Passo 6: Compara√ß√£o R√°pida

```bash
python compare.py
```

Exibe uma compara√ß√£o r√°pida no console.

## üìä M√©tricas Utilizadas

### 1. Acur√°cia Factual
Verifica se a resposta cont√©m a informa√ß√£o factual esperada (ground truth).

### 2. Acur√°cia de Coer√™ncia
Verifica se a resposta tem frases completas e bem formadas.

### 3. Acur√°cia Geral
Combina√ß√£o de ambas as m√©tricas acima.

## üî¨ Testes de Signific√¢ncia

O projeto utiliza **testes Z para propor√ß√µes** para determinar se as melhorias observadas s√£o estatisticamente significativas:

- **p < 0.01**: Altamente significativo (***)
- **p < 0.05**: Significativo (**)
- **p ‚â• 0.05**: N√£o significativo (ns)

## üìà Interpretando os Resultados

### Prova de Efic√°cia do TDD

O TDD ajuda a ter mais acerto quando:

1. **Melhoria positiva**: As m√©tricas de TDD s√£o maiores que baseline
2. **Signific√¢ncia estat√≠stica**: p-value < 0.05 em pelo menos uma m√©trica
3. **Consist√™ncia**: Melhorias observadas em m√∫ltiplas m√©tricas

### Exemplo de Resultado Prova Efic√°cia

```
M√âTRICAS DE PRECIS√ÉO
------------------------------------------------------------
BASELINE (sem TDD):
  Acur√°cia Factual:    33.33% (3/9)
  Acur√°cia Coer√™ncia:  88.89% (8/9)
  Acur√°cia Geral:      33.33% (3/9)

TDD (com refinamento):
  Acur√°cia Factual:    66.67% (6/9)  ‚Üê +33.34 pontos percentuais
  Acur√°cia Coer√™ncia:  100.00% (9/9) ‚Üê +11.11 pontos percentuais
  Acur√°cia Geral:      66.67% (6/9)  ‚Üê +33.34 pontos percentuais

TESTES DE SIGNIFIC√ÇNCIA ESTAT√çSTICA
------------------------------------------------------------
FACTUAL:
  p-value:  0.0234
  ‚úì SIGNIFICATIVO (p < 0.05)
```

## üìÅ Estrutura de Arquivos

```
.
‚îú‚îÄ‚îÄ generate_responses.py          # Gera respostas baseline
‚îú‚îÄ‚îÄ pipeline_tdd_improved.py      # Pipeline TDD com refinamento
‚îú‚îÄ‚îÄ statistical_analysis.py       # An√°lise estat√≠stica completa
‚îú‚îÄ‚îÄ visualize_results.py          # Gera visualiza√ß√µes
‚îú‚îÄ‚îÄ compare.py                    # Compara√ß√£o r√°pida
‚îú‚îÄ‚îÄ prompts.json                  # Perguntas de teste
‚îú‚îÄ‚îÄ ground_truth.json             # Respostas esperadas
‚îú‚îÄ‚îÄ responses_raw.json            # Respostas baseline (gerado)
‚îú‚îÄ‚îÄ validated_tdd_improved.json   # Respostas TDD (gerado)
‚îú‚îÄ‚îÄ statistical_report.json       # Relat√≥rio estat√≠stico (gerado)
‚îú‚îÄ‚îÄ comparison.json               # Compara√ß√£o JSON (gerado)
‚îú‚îÄ‚îÄ report.html                   # Relat√≥rio HTML (gerado)
‚îî‚îÄ‚îÄ tests/                        # Testes unit√°rios
    ‚îú‚îÄ‚îÄ test_factual_accuracy.py
    ‚îî‚îÄ‚îÄ test_coherence.py
```

## üß™ Executando Testes

```bash
pytest tests/
```

## üìù Requisitos

Instale as depend√™ncias:

```bash
pip install -r requirements.txt
```

Principais depend√™ncias:
- `google-generativeai`: API do Gemini
- `scipy`: Testes estat√≠sticos
- `matplotlib`: Visualiza√ß√µes
- `pandas`: An√°lise de dados
- `pytest`: Testes unit√°rios

## üéì Conclus√£o

Este projeto fornece uma **prova estat√≠stica** de que TDD melhora a precis√£o das respostas de LLMs atrav√©s de:

1. ‚úÖ M√©tricas quantitativas comparativas
2. ‚úÖ Testes de signific√¢ncia estat√≠stica
3. ‚úÖ Visualiza√ß√µes claras
4. ‚úÖ Relat√≥rios detalhados

Os resultados demonstram que o uso de testes como feedback iterativo permite refinar respostas at√© que crit√©rios de qualidade sejam atendidos, resultando em maior precis√£o factual e coer√™ncia textual.

